---
title: "Predicting transactions in different countries with logistic, LDA, QDA and KNN classifiers"
author: 'Lixia'
date: '2020/12/22'
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Preface

This project will use trade data (trade_data.csv) to evaluate performance of logistic, LDA, QDA and KNN classifiers. It will be predicting whether two countries have trade or not. In other words, before proceeding with any of the problems in this project, people should create a binary variable "trade" which takes two values, i.e., 0 or 1. If ln_trade = "NA", then trade = 0; if ln_trade is positive, then trade = 1. There are two independent variables, i.e., common_lang and ln_distance.  


### 1. logistic regression

Fit logistic regression model of the binary categorical outcome (trade=1 or not) using two independent variables as predictors in the model. Calculate confusion matrix and accuracy. 

```{r 0}
# process the data
trade_data=read.csv("trade_data.csv")
trade_data$ln_trade <- ifelse(trade_data$ln_trade > 0,1,0)
trade_data$ln_trade[is.na(trade_data$ln_trade)] <- 0
names(trade_data)
dim(trade_data)
summary(trade_data)
cor(trade_data[,-1:-2])
```

The data set has 24806 rows and 5 columns. In the fifth column, if ln_trade = "NA", then trade = 0; if ln_trade is positive, then trade = 1. The relationship between common_lang and ln_trade is  positive. However, the relationship between ln_distance and ln_trade is negative.

```{r 1}
#logistic regression
attach(trade_data)
library(ISLR)
glm.fits=glm(ln_trade~common_lang+ln_distance, data=trade_data,family=binomial)
summary(glm.fits)
glm.probs=predict(glm.fits,type="response")
glm.probs[1:10]
glm.pred=rep("0",24806)
glm.pred[glm.probs >.5]="1"
table(glm.pred,ln_trade)
(12208+2169)/24806
mean(glm.pred==ln_trade)
```

The accuracy is 0.5795775. it almost always predicts "0".

### 2. LDA and QDA

Fit LDA and QDA classifiers on the entire dataset and calculate confusion matrix and accuracy for each of them. Compare them to those of logistic regression. 

```{r 2a}
# LDA 
attach(trade_data)
library(MASS)
lda.fit=lda(ln_trade ~ common_lang + ln_distance, trade_data)
lda.fit
lda.pred=predict(lda.fit)
names(lda.pred)
lda.class=lda.pred$class
lda.class[1:10]
table(lda.class,trade_data$ln_trade)
(12199+2172)/24806
mean(lda.class==trade_data$ln_trade)
```

The accuracy of LDA is 0.5793356. The result is very similar to Logistic regression.

```{r 2b}
# QDA
attach(trade_data)
library(MASS)
qda.fit=qda(ln_trade ~ common_lang + ln_distance, trade_data)
qda.fit
qda.pred=predict(qda.fit,trade_data)
names(qda.pred)
qda.class=qda.pred$class
head(qda.class)
table(qda.class,trade_data$ln_trade)
mean(qda.class==trade_data$ln_trade)
```

The accuracy of QDA model is 0.5794163.

### 3. KNN

Fit KNN classifiers for the entire dataset and calculate confusion matrix and accuracy for $k=40$ nearest neighbors models.  Compare them to the corresponding results from LDA, QDA and logistic regression. 

```{r 3}
# KNN
attach(trade_data)
library(class)
trainX=trade_data[1:22326,3:4]
testX=trade_data[22327:24806,3:4]
trainY=trade_data[1:22326,5]
testY=trade_data[22327:24806,5]
set.seed(1234)
knn.pred = knn(trainX, testX, trainY, k = 40)
table(knn.pred,testY )
mean(knn.pred==testY)
```

For the KNN classifiers, We separated the training set and  the test set by a percentage of 90 and 10. The accuracy is 0.5802419. It is a little higher than the previous three models.

```{r 3+}
# Another KNN model for 20000 and 4806
# Please know that this KNN model will not be used
attach(trade_data)
library(class)
trainX=trade_data[1:20000,3:4]
testX=trade_data[20001:24806,3:4]
trainY=trade_data[1:20000,5]
testY=trade_data[20001:24806,5]
set.seed(1234)
knn.pred = knn(trainX, testX, trainY, k = 40)
table(knn.pred,testY )
mean(knn.pred==testY)

```

Please know that the KNN model which separated by 20000 and 4806 will not be used for the final comparison. The accuracy is not good. It is terrible. 

### 4. compare test accuracy of logistic regression, LDA, QDA and KNN

Randomly select 20000 observations as the training data and the other 4806 observations as the test data. Use the training data for estimation and the test data for prediction. Calculate the accuracy using each of these methods (logistic regression, LDA, QDA, KNN). Discuss their relative performance. 

```{r 4a0}
# Process the data
library(tidyverse)
data0 <- read.csv("trade_data.csv")
data1 <- data0 %>%
  transmute(trade = 1 - as.numeric(is.na(ln_trade)),
            common_lang = common_lang,
            ln_distance1 = scale(ln_distance))
names(data1)
dim(data1)
head(data1)
cor(data1)
summary(data1)
```

The data set has 24806 rows and 3 columns. In the first column, if ln_trade = "NA", then trade = 0; if ln_trade is positive, then trade = 1. The relationship between common_lang and trade is  positive again. And the relationship between ln_distance and trade is negative.

```{r 4a1}
# logistic regression
set.seed(1234)
train0 <- sample(1:24806, 20000)
train1 <- data1[train0, ]
test1 <- data1[-train0, ]

fit1 <- glm(trade ~ common_lang + ln_distance1, train1, family = binomial)
summary(fit1)
summary(fit1)$coef

pred1 <- predict(fit1, test1, type = "response")
glm.probs <- predict(fit1, test1, type = "response")

glm.pred <- rep("0", 4806)
glm.pred[glm.probs >.5]="1"
table(glm.pred, test1[, "trade"])
mean(glm.pred == test1[, "trade"])
```

The accuracy is 0.5751144. 

```{r 4b}
# LDA
attach(data1)
set.seed(1234)
library(MASS)
lda.fit=lda(trade ~ common_lang + ln_distance1, train1)
lda.fit
lda.pred=predict(lda.fit , test1)
lda.class=lda.pred$class
head(lda.class)
tail(lda.class)
table(lda.class ,test1[, "trade"])
mean(lda.class==test1[, "trade"])
```

The accuracy is 0.5751144. It is similar to  the Logistic regression above.

```{r 4c}
# QDA
attach(data1)
set.seed(1234)
library(MASS)
qda.fit=qda(trade ~ common_lang + ln_distance1, train1)
qda.pred=predict(qda.fit,test1)
qda.class=qda.pred$class
head(qda.class)
table(qda.class,test1[, "trade"])
mean(qda.class==test1[, "trade"])
```

The accuracy is 0.5763629. It performs better than the LDA model.

```{r 4d}
# KNN
attach(data1)
library(class)
set.seed(1234)
train0 <- sample(1:24806, 20000)
trainA=data1[train0,2:3 ]
testA=data1[-train0,2:3 ]
trainB=data1[train0,1 ]
testB=data1[-train0,1]
knn.pred = knn(trainA, testA, trainB, k = 40)
table(knn.pred,testB )
mean(knn.pred==testB)
```

The accuracy is 0.5740741. It doesn't seem to perform better than the previous three models.

```{r 5}
# bonus 
A=matrix(c(0.5795775,0.5793356,0.5794163,0.5802419),nrow=1)
B=matrix(c(0.5751144,0.5751144,0.5763629,0.5740741),nrow=1)
Compare_part=rbind(A,B)
colnames(Compare_part)=c('Logistic','LDA','QDA','KNN')
rownames(Compare_part)=c('accuracy_Q1~Q3','accuracy_Q4')
Compare_part
max(Compare_part)
which.max(Compare_part)
```

The best model is the first KNN model which separated the training set and  test set by a percentage of 90 and 10.

