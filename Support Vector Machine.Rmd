---
title: "Support Vector Machine"
author: "Lixia"
date: '2022-11-23'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Support Vector Classifier

```{r}
# generate the observations that belong to two classes and check whether the classes are linearly separable
set.seed(1)
x=matrix(rnorm (20*2), ncol=2)
y=c(rep(-1,10), rep(1,10))
x[y==1,]=x[y==1,] + 1
plot(x, col=(3-y))
```


```{r}
# fit and plot the support vector classifier
dat=data.frame(x=x, y=as.factor(y))
library(e1071)
svmfit=svm(y~., data=dat , kernel ="linear", cost=10, scale=FALSE)
plot(svmfit , dat)
```


```{r}
# obtain some basic information about the support vector classifier fit
svmfit$index
summary(svmfit)
```


```{r}
# instead used a smaller value of the cost parameter
svmfit=svm(y~., data=dat , kernel ="linear", cost =0.1,scale=FALSE)
plot(svmfit , dat)
svmfit$index
```


```{r}
# performs cross-validation
set.seed(1)
tune.out=tune(svm ,y~.,data=dat,kernel ="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
summary (tune.out)
bestmod=tune.out$best.model
summary(bestmod)
```


```{r}
# predict the class label on a set of test observations
xtest=matrix(rnorm (20*2) , ncol=2)
ytest=sample (c(-1,1), 20, rep=TRUE)
xtest[ytest==1,]= xtest[ytest==1,] + 1
testdat=data.frame(x=xtest , y=as.factor(ytest))
ypred=predict (bestmod ,testdat)
table(predict =ypred , truth=testdat$y )
```

Support Vector Machine

```{r}
# generate some data with a non-linear class boundary
set.seed(1)
x=matrix(rnorm (200*2) , ncol=2)
x[1:100,]=x[1:100,]+2
x[101:150 ,]=x[101:150,]-2
y=c(rep(1,150) ,rep(2,50))
dat=data.frame(x=x,y=as.factor(y))
plot(x, col=y)
```


```{r}
# randomly split the data into training and testing groups
train=sample (200,100)
svmfit=svm(y~., data=dat[train ,], kernel ="radial", gamma=1,cost=1)
plot(svmfit , dat[train ,])
summary(svmfit)
```


```{r}
# perform cross-validation using tune() to select the best choice
set.seed(1)
tune.out=tune(svm, y~., data=dat[train,], kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),
            gamma=c(0.5,1,2,3,4) ))
summary (tune.out)
table(true=dat[-train,"y"], pred=predict (tune.out$best.model,newdata =dat[-train ,]))
```

